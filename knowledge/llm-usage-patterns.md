# LLM 使用技巧與痛點分析 (LLM Usage Patterns)

> 從「亂問一通」到「專家協調」：如何極大化大語言模型的產出品質。

---

## 核心痛點：高維工具 vs. 低維問法

LLM 是具備極高維度知識空間的工具，但最常見的失敗來自於使用者的「直覺式提問」：
1. **模糊性**：輸入「幫我寫個股票腳本」，AI 會隨機選擇它認為的範例，而非你需要的。
2. **幻覺**：當指令缺乏約束時，AI 傾向於提供「看起來正確」而非「事實正確」的答案。
3. **上下文迷失**：隨著對話過長，AI 會遺忘最初的系統約束。

---

## 進階技巧：從「問答」轉向「架構」

### 1. 專家定義 (Persona & Expert System)
與其對著空白視窗說話，不如賦予 AI 一個明確的「靈魂」。
- **技巧**：使用 `system_prompt` 或專屬 `prompt.md` 定義專家角色。
- **本專案實踐**：建立 [[advisor-prompt]]、[[pm-prompt]]、[[cto-prompt]]。當 AI 知道它是 CTO 時，它會更關注「技術債」而非單純完成功能。

### 2. 混合專家模型 (MIxture of Experts, MoE)
在單一模型中模擬多路思維，讓不同觀點進行對撞。
- **技巧**：要求 AI 同時扮演多個角色並進行內部辯論。
- **本專案實踐**：[[advisor-sync]] 工作流。透過 Advisor 分析、CIO 挑戰、CSO 決策的鏈式流程，模擬 MoE 架構來產出更穩健的結論。

### 3. Workflow 拆解 (Process Orientation)
不要試圖在一句話內完成所有事（One-shot failure）。
- **原則**：將複雜問題拆解為「資料抓取」->「初步分析」->「壓力測試」->「最終決策」。
- **優勢**：每一點都能獲得模型最大的注意力資源，且容易定位錯誤。

---

## 避坑指南

| 痛點                  | 解決技巧                                   | 備註                                         |
| --------------------- | ------------------------------------------ | -------------------------------------------- |
| **AI 開始胡言亂語**   | 使用「強制檢查清單 (Mandatory Checklist)」 | 在 prompt 結尾要求 AI 逐項確認               |
| **代碼過於冗長/低效** | 給予「限制條件 (Constraints)」             | 例如：優先重用現有的 Utils、禁止使用特定套件 |
| **遺忘初衷**          | 執行 [[commit]] 工作流                     | 透過檔案存檔將知識固化，而非只留在對話緩存中 |

---

## 總結：大腦的擴張
LLM 不是百科全書，而是「思維的協助手」。透過 [[workflow-vs-prompt]] 的分離，我們能將確定性的流程交給電腦，將判斷性的權重交給 AI。

---

## 相關連結

- [[workflow-vs-prompt]] - 核心設計原則
- [[ai-advisor-system]] - 本專案的專家體系實踐
- [[cto-prompt]] - 技術審查專用角色
